---
title: "MA615 Twitter Data Mining Projct"
subtitle: "Smart Home"
author: "Mengyun Li"
date: "Dec 4, 2017"
output: html_document
always_allow_html: yes
---

```{r setup, include=FALSE, warning= FALSE}
knitr::opts_chunk$set(echo = FALSE)
library(plyr)
library(devtools)
library(twitteR)
library(tidyverse)
library(streamR)
library(wordcloud)
library(tm)
library(SnowballC)
library(stringr)
library(RColorBrewer)
library(reshape2)
library(sentimentr)
library(ggplot2)
library(tidytext)
library(ggmap)
library(maptools)
library(maps)
library(gridExtra)
library(leaflet)
library(knitr)

```



```{r, , warning= FALSE}
api_key <- 	"a7mnlj2IxKAx5HQPyp47RSDcF"
api_secret <- "tWhIRKBBFR3AAPhS8pJYfjywos1pxXcymjPsSKDKAjwkByHHeW"
access_token <- "927637519667269632-t5qJ7vvlWcgBb6ZQpSqsdC1TOznasxj"
access_token_secret <- "n3RCUHtWsPh0cFKniMzz0DN1d7qSRVQZVAMYht7qBsUGs"

setup_twitter_oauth(api_key, api_secret, access_token, access_token_secret)
```
# 1. Introduction: What is Smart Home ?

Smart Home is building automation for a home. It involves the control and automation of lighting, heating (such as smart thermostats), ventilation, air conditioning (HVAC), and security, as well as home appliances such as washer/dryers, ovens or refrigerators/freezers. Wi-Fi is often used for remote monitoring and control. Home devices, when remotely monitored and controlled via the Internet, are an important constituent of the Internet of Things.

This analysis compares two smart home product I like most, Google Home Mini and Echo Dot. Through Google Home I can get hands-free help from the Google Assistant. Get answers, play songs, tackle your day, enjoy your entertainment and control your smart home with just my voice. Echo Pot is a similar product made by Amazon"

For more information, visit product webpage. 
Google home: https://store.google.com/product/google_home
Echo Dot:https://www.amazon.com/Amazon-Echo-Dot-Previous-Generation/b?ie=UTF8&node=14047587011
```{r, warning= FALSE}
smarthome1 <- searchTwitter('smarthome',since = "2010-01-01", until = "2017-12-15", lang = "en", n = 20000)
smarthome1 <- twListToDF(smarthome1)
#twitter data for mapping
smarthome.df<-subset(smarthome1, !is.na(smarthome1$latitude))
saveRDS(smarthome.df, file="smarthome_geo.rds")

smarthome <- searchTwitter('smarthome',since = "2017-01-01", until = "2017-12-15", lang = "en", n = 2000)
smarthome <- twListToDF(smarthome)
saveRDS(smarthome, file="SmartHome.rds")

```

# 2. Word cloud - A helicopter View

##"Home Smart"
```{r}
smarthome$text <- iconv(smarthome$text,from = "latin1", to = "ASCII", sub = "")
## Create a corpus.
wordCorpus <- Corpus(VectorSource(str_replace_all(smarthome$text, "@","")))
## Convert the corpus to a plain text document.
wordCorpus <- tm_map(wordCorpus, PlainTextDocument)
## Remove all punctuation and stopwords.
wordCorpus <- tm_map(wordCorpus, removePunctuation)
wordCorpus <- tm_map(wordCorpus, content_transformer(tolower))
wordCorpus <- tm_map(wordCorpus, removeWords, stopwords('english'))
wordCorpus <- tm_map(wordCorpus, removeWords, c('the', 'this', stopwords('english')))
wordCorpus <- tm_map(wordCorpus, removeWords, c('smarthome'))

## Perform stemming.
wordCorpus <- tm_map(wordCorpus, stemDocument)

## Plot
set.seed(123)
wordcloud(wordCorpus, scale=c(5,0.5), max.words = 80, random.order = FALSE, rot.per=0.35, use.r.layout=FALSE, colors = brewer.pal(4, "Dark2"))

```
## "Google Home"

```{r}
googlehome <- searchTwitter('googlehome',since = "2015-01-01", until = "2017-12-15", lang = "en", n = 2000)
googlehome <- twListToDF(googlehome)
saveRDS(googlehome, file="googlehome.rds")

googlehome$text <- iconv(googlehome$text,from = "latin1", to = "ASCII", sub = "")
## Create a corpus.
wordCorpus2 <- Corpus(VectorSource(str_replace_all(googlehome$text, "@","")))
## Convert the corpus to a plain text document.
wordCorpus2 <- tm_map(wordCorpus2, PlainTextDocument)
## Remove all punctuation and stopwords.
wordCorpus2 <- tm_map(wordCorpus2, removePunctuation)
wordCorpus2 <- tm_map(wordCorpus2, content_transformer(tolower))
wordCorpus2 <- tm_map(wordCorpus2, removeWords, stopwords('english'))
wordCorpus2 <- tm_map(wordCorpus2, removeWords, c('the', 'this', stopwords('english')))
wordCorpus2 <- tm_map(wordCorpus2, removeWords, c('smarthome'))

## Perform stemming.
wordCorpus2 <- tm_map(wordCorpus2, stemDocument)

## Plot
set.seed(123)
wordcloud(wordCorpus2, scale=c(5,0.5), max.words = 80, random.order = FALSE, rot.per=0.35, use.r.layout=FALSE, colors = brewer.pal(4, "Dark2"))
```

## "Echo Dot"

```{r}
echodot <- searchTwitter('echodot',since = "2015-01-01", until = "2017-12-15", lang = "en", n = 2000)
echodot <- twListToDF(echodot)

echodot <- readRDS('echodot.rds')
echodot$text <- iconv(echodot$text,from = "latin1", to = "ASCII", sub = "")
## Create a corpus.
wordCorpus1 <- Corpus(VectorSource(str_replace_all(echodot$text, "@","")))
## Convert the corpus to a plain text document.
wordCorpus1 <- tm_map(wordCorpus1, PlainTextDocument)
## Remove all punctuation and stopwords.
wordCorpus1 <- tm_map(wordCorpus1, removePunctuation)
wordCorpus1 <- tm_map(wordCorpus1, content_transformer(tolower))
wordCorpus1 <- tm_map(wordCorpus1, removeWords, stopwords('english'))
wordCorpus1 <- tm_map(wordCorpus1, removeWords, c('the', 'this', stopwords('english')))
wordCorpus1 <- tm_map(wordCorpus1, removeWords, c('smarthome'))

## Perform stemming.
wordCorpus1 <- tm_map(wordCorpus1, stemDocument)
## Plot
set.seed(123)
wordcloud(wordCorpus1, scale=c(5,0.5), max.words = 80, random.order = FALSE, rot.per=0.35, use.r.layout=FALSE, colors = brewer.pal(4, "Dark2"))
```


# 3. Sentiment Analysis

```{r}
pos.words <- scan("positive-words.txt",what="character",comment.char=";")
neg.words <- scan("negative-words.txt",what="character",comment.char=";")

pos.words = c(pos.words, 'new','nice' ,'good', 'horizon','best','perfect')
neg.words = c(neg.words, 'wtf', 'behind','feels', 'ugly', 'back','worse' , 'shitty', 'bad', 'no','freaking','sucks','horrible')

score.sentiment = function(sentences, pos.words, neg.words, .progress='none')
{
	require(plyr)
	require(stringr)
	
	# we got a vector of sentences. plyr will handle a list or a vector as an "l" for us
	# we want a simple array of scores back, so we use "l" + "a" + "ply" = laply:
	scores = laply(sentences, function(sentence, pos.words, neg.words) {
		
		# clean up sentences with R's regex-driven global substitute, gsub():
		sentence = gsub('[[:punct:]]', '', sentence)
		sentence = gsub('[[:cntrl:]]', '', sentence)
		sentence = gsub('\\d+', '', sentence)
		# and convert to lower case:
		sentence = tolower(sentence)

		# split into words. str_split is in the stringr package
		word.list = str_split(sentence, '\\s+')
		# sometimes a list() is one level of hierarchy too much
		words = unlist(word.list)

		# compare our words to the dictionaries of positive & negative terms
		pos.matches = match(words, pos.words)
		neg.matches = match(words, neg.words)
	
		# match() returns the position of the matched term or NA
		# we just want a TRUE/FALSE:
		pos.matches = !is.na(pos.matches)
		neg.matches = !is.na(neg.matches)

		# and conveniently enough, TRUE/FALSE will be treated as 1/0 by sum():
		score = sum(pos.matches) - sum(neg.matches)

		return(score)
	}, pos.words, neg.words, .progress=.progress )

	scores.df = data.frame(score=scores, text=sentences)
	return(scores.df)
}

echodot <- readRDS("echodot.rds")
echodot$text <- str_replace_all(echodot$text, "@", "")
echodot$text <- str_replace_all(echodot$text, "#", "")
result_echo <- score.sentiment(echodot$text,pos.words,neg.words)

bar_echo <- ggplot(result_echo,aes(result_echo$score))+geom_bar(width = 0.3)

googlehome <- readRDS("googlehome.rds")
googlehome$text <- str_replace_all(googlehome$text, "@", "")
googlehome$text <- str_replace_all(googlehome$text, "#", "")
result_google <- score.sentiment(googlehome$text,pos.words,neg.words)

bar_google <- ggplot(result_google,aes(result_google$score))+geom_bar(width = 0.3)
saveRDS(result_echo, file="result_echo.rds")
saveRDS(result_google, file="result_google.rds")

grid.arrange(bar_echo, bar_google, ncol=2)
```


```{r}
mapdata<-readRDS("smarthome_geo.rds")
mapdata$longitude<-as.numeric(mapdata$longitude)
mapdata$latitude<-as.numeric(mapdata$latitude)
x <- mapdata$longitude
y <- mapdata$latitude

leaflet(data = mapdata)%>%
  addTiles()%>%
  addCircleMarkers(~x,~y, col="red")

```


```{r}
smarthome <- readRDS("SmartHome.rds")
smarthome$favoriteCount <- as.numeric(smarthome$favoriteCount)

timeline1 <- ggplot(smarthome, aes(x=created, y=favoriteCount)) +
  geom_line(col='orange')+labs(x="Time", y="Number of Favourates")
timeline2 <- ggplot(smarthome, aes(x=created, y=retweetCount)) +
  geom_line(col='orange')+ labs(x="Time", y="Number of Retweets")

grid.arrange(timeline1, timeline2, ncol=2)
```








